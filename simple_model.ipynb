{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15eac188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./data/augmented_data.csv')\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = data.drop('success', axis=1)\n",
    "y = data['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc2fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0baf1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Features:\n",
      "shs_gpa                                                              0.188895\n",
      "p2                                                                   0.203887\n",
      "p5                                                                   0.149366\n",
      "p14                                                                  0.130378\n",
      "p21                                                                  0.129414\n",
      "p23                                                                  0.156769\n",
      "p25                                                                  0.123879\n",
      "p26                                                                  0.113198\n",
      "p30                                                                  0.164153\n",
      "p31                                                                  0.105196\n",
      "p33                                                                  0.145390\n",
      "s9                                                                   0.150483\n",
      "s18                                                                  0.116876\n",
      "s19                                                                  0.151940\n",
      "program_BS Computer Science                                          0.132669\n",
      "program_BS Information Technology                                   -0.139208\n",
      "strand_ABM/BAM                                                       0.111339\n",
      "class_rank_None                                                     -0.104173\n",
      "class_rank_Top 5                                                     0.121341\n",
      "academic_awards_None                                                -0.138611\n",
      "academic_awards_With Honor                                           0.113013\n",
      "classroom_org_None                                                  -0.145272\n",
      "fathers_education_High school graduate, diploma or the equivalent   -0.120102\n",
      "mothers_employment_Not Applicable (no work, not known, etc.)         0.103761\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between features and the target variable\n",
    "correlations = X_train.corrwith(y_train)\n",
    "\n",
    "# Set a threshold for considering high correlation\n",
    "threshold = 0.1\n",
    "\n",
    "# Find the highly correlated features\n",
    "highly_correlated_features = correlations[correlations.abs() >= threshold]\n",
    "\n",
    "# Print the highly correlated features\n",
    "print(\"Highly Correlated Features:\")\n",
    "print(highly_correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad03726",
   "metadata": {},
   "source": [
    "### Classical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d2327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a k-fold cross-validation object\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_cv_scores = cross_val_score(svm_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "svm_accuracy = svm_cv_scores.mean()\n",
    "\n",
    "# Decision Tree (DT) model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_cv_scores = cross_val_score(dt_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "dt_accuracy = dt_cv_scores.mean()\n",
    "\n",
    "# Neural Network (NN) model\n",
    "nn_model = MLPClassifier()\n",
    "nn_cv_scores = cross_val_score(nn_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "nn_accuracy = nn_cv_scores.mean()\n",
    "\n",
    "# Train the models on the full training set\n",
    "svm_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "nn_predictions = nn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92cf74c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "            Model  CV Accuracy  Accuracy  F1-Score  Precision    Recall  \\\n",
      "0             SVM     0.742385  0.818182  0.817717   0.818182  0.821462   \n",
      "1   Decision Tree     0.766380  0.813131  0.812744   0.813673  0.816875   \n",
      "2  Neural Network     0.886378  0.914141  0.913646   0.912643  0.915833   \n",
      "\n",
      "        AUC      Confusion Matrix  \n",
      "0  0.821462  [[86, 23], [13, 76]]  \n",
      "1  0.816875  [[85, 24], [13, 76]]  \n",
      "2  0.915833   [[98, 11], [6, 83]]  \n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "svm_report = classification_report(y_test, svm_predictions, output_dict=True)\n",
    "svm_auc = roc_auc_score(y_test, svm_predictions)\n",
    "\n",
    "dt_report = classification_report(y_test, dt_predictions, output_dict=True)\n",
    "dt_auc = roc_auc_score(y_test, dt_predictions)\n",
    "\n",
    "nn_report = classification_report(y_test, nn_predictions, output_dict=True)\n",
    "nn_auc = roc_auc_score(y_test, nn_predictions)\n",
    "\n",
    "# Calculate confusion matrix for each model\n",
    "svm_confusion = confusion_matrix(y_test, svm_predictions)\n",
    "dt_confusion = confusion_matrix(y_test, dt_predictions)\n",
    "nn_confusion = confusion_matrix(y_test, nn_predictions)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['SVM', 'Decision Tree', 'Neural Network'],\n",
    "    'CV Accuracy': [svm_accuracy, dt_accuracy, nn_accuracy],\n",
    "    'Accuracy': [svm_model.score(X_test, y_test), dt_model.score(X_test, y_test), nn_model.score(X_test, y_test)],\n",
    "    'F1-Score': [svm_report['macro avg']['f1-score'], dt_report['macro avg']['f1-score'], nn_report['macro avg']['f1-score']],\n",
    "    'Precision': [svm_report['macro avg']['precision'], dt_report['macro avg']['precision'], nn_report['macro avg']['precision']],\n",
    "    'Recall': [svm_report['macro avg']['recall'], dt_report['macro avg']['recall'], nn_report['macro avg']['recall']],\n",
    "    'AUC': [svm_auc, dt_auc, nn_auc],\n",
    "    'Confusion Matrix': [svm_confusion, dt_confusion, nn_confusion]\n",
    "})\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3e0ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Feature Importances (SVM Linear):\n",
      "                                               Feature  SVM Importance\n",
      "92   classroom_org_I forgot already, might be just ...        1.676340\n",
      "166                                       s25_Leave it        1.427534\n",
      "72                   program_BS Information Technology        1.397573\n",
      "151                         mothers_employment_Retired        1.340495\n",
      "108                         school_org_Project Manager        1.312652\n",
      "157                         income_P50,000 to P100,000        1.267727\n",
      "102                                 school_org_Auditor        1.239745\n",
      "145      mothers_employment_Disabled, not able to work        1.233484\n",
      "139  mothers_education_Not Applicable (no work, not...        1.231842\n",
      "174                          s26_More than 4 hours/day        1.177111\n"
     ]
    }
   ],
   "source": [
    "# Obtain feature importances for linear SVM model\n",
    "svm_feature_importances = abs(svm_model.coef_[0])\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'SVM Importance': svm_feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by SVM Importance values in descending order\n",
    "importances_df = importances_df.sort_values(by='SVM Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 feature importances\n",
    "top_10_importances = importances_df.head(10)\n",
    "print(\"Top 10 Feature Importances (SVM Linear):\")\n",
    "print(top_10_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7043303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Top 10 Feature Importances:\n",
      "     Feature  Importance\n",
      "65       s19    0.072260\n",
      "6    shs_gpa    0.057699\n",
      "1    english    0.047243\n",
      "2    reading    0.041109\n",
      "5   abstract    0.040922\n",
      "3    science    0.038781\n",
      "7         p1    0.035635\n",
      "61       s15    0.035396\n",
      "43       p37    0.032524\n",
      "29       p23    0.030959\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for feature importances\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': dt_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance values in descending order\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 feature importances\n",
    "top_10_importances = importances_df.head(10)\n",
    "print(\"DT Top 10 Feature Importances:\")\n",
    "print(top_10_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cb4a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Feature Importances (Neural Network):\n",
      "                    Feature  NN Importance\n",
      "13                       p7       0.028392\n",
      "33                      p27       0.026887\n",
      "11                       p5       0.023179\n",
      "69                      s23       0.017305\n",
      "97  classroom_org_President       0.016480\n",
      "56                      s10       0.014477\n",
      "80            strand_TVL-HE       0.014214\n",
      "34                      p28       0.013899\n",
      "49                       s3       0.013504\n",
      "66                      s20       0.013022\n"
     ]
    }
   ],
   "source": [
    "# Obtain feature importances for Neural Network model\n",
    "nn_feature_importances = abs(nn_model.coefs_[0].mean(axis=0))\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns[:len(nn_feature_importances)],\n",
    "    'NN Importance': nn_feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by NN Importance values in descending order\n",
    "importances_df = importances_df.sort_values(by='NN Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 feature importances\n",
    "top_10_importances = importances_df.head(10)\n",
    "print(\"Top 10 Feature Importances (Neural Network):\")\n",
    "print(top_10_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a2b9b",
   "metadata": {},
   "source": [
    "### Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b86e0765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the ensemble model using Voting Classifier\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('svm', svm_model), ('dt', dt_model), ('nn', nn_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Perform k-fold cross-validation on the ensemble model\n",
    "ensemble_cv_scores = cross_val_score(ensemble_model, X_train, y_train, cv=kf)\n",
    "ensemble_accuracy = ensemble_cv_scores.mean()\n",
    "\n",
    "# Train the ensemble model on the full training set\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "ensemble_predictions = ensemble_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the ensemble model\n",
    "ensemble_report = classification_report(y_test, ensemble_predictions, output_dict=True)\n",
    "ensemble_auc = roc_auc_score(y_test, ensemble_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2079fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ensemble model using Bagging Classifier\n",
    "bagging_model = BaggingClassifier(base_estimator=SVC(kernel='linear'), n_estimators=10)\n",
    "bagging_cv_scores = cross_val_score(bagging_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "bagging_accuracy = bagging_cv_scores.mean()\n",
    "\n",
    "# Train the model on the full training set\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "bagging_predictions = bagging_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "bagging_report = classification_report(y_test, bagging_predictions, output_dict=True)\n",
    "bagging_auc = roc_auc_score(y_test, bagging_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a5deabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jaydee\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the ensemble model using Stacking Classifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('SVM', svm_model), ('Decision Tree', dt_model), ('Neural Network', nn_model)],\n",
    "    final_estimator=SVC(kernel='linear')\n",
    ")\n",
    "\n",
    "stacking_cv_scores = cross_val_score(stacking_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "stacking_accuracy = stacking_cv_scores.mean()\n",
    "\n",
    "# Train the model on the full training set\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "stacking_predictions = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "stacking_report = classification_report(y_test, stacking_predictions, output_dict=True)\n",
    "stacking_auc = roc_auc_score(y_test, stacking_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d186b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Results:\n",
      "      Model  CV Accuracy  Accuracy  F1-Score  Precision    Recall       AUC  \\\n",
      "0  Ensemble     0.866189  0.934343  0.933964   0.932897  0.936244  0.936244   \n",
      "1   Bagging     0.787891  0.858586  0.857407   0.856835  0.858159  0.858159   \n",
      "2  Stacking     0.882533  0.939394  0.938636   0.939733  0.937738  0.937738   \n",
      "\n",
      "       Confusion Matrix  \n",
      "0   [[100, 9], [4, 85]]  \n",
      "1  [[94, 15], [13, 76]]  \n",
      "2   [[104, 5], [7, 82]]  \n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix for each model\n",
    "ensemble_confusion = confusion_matrix(y_test, ensemble_predictions)\n",
    "bagging_confusion = confusion_matrix(y_test, bagging_predictions)\n",
    "stacking_confusion = confusion_matrix(y_test, stacking_predictions)\n",
    "\n",
    "# Create a DataFrame for the ensemble models\n",
    "ensemble_results = pd.DataFrame({\n",
    "    'Model': ['Ensemble', 'Bagging', 'Stacking'],\n",
    "    'CV Accuracy': [ensemble_accuracy, bagging_accuracy, stacking_accuracy],\n",
    "    'Accuracy': [ensemble_model.score(X_test, y_test), bagging_model.score(X_test, y_test), stacking_model.score(X_test, y_test)],\n",
    "    'F1-Score': [ensemble_report['macro avg']['f1-score'], bagging_report['macro avg']['f1-score'], stacking_report['macro avg']['f1-score']],\n",
    "    'Precision': [ensemble_report['macro avg']['precision'], bagging_report['macro avg']['precision'], stacking_report['macro avg']['precision']],\n",
    "    'Recall': [ensemble_report['macro avg']['recall'], bagging_report['macro avg']['recall'], stacking_report['macro avg']['recall']],\n",
    "    'AUC': [ensemble_auc, bagging_auc, stacking_auc],\n",
    "    'Confusion Matrix': [ensemble_confusion, bagging_confusion, stacking_confusion]\n",
    "})\n",
    "\n",
    "# Print the results of the ensemble models\n",
    "print(\"Ensemble Model Results:\")\n",
    "print(ensemble_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb233f0",
   "metadata": {},
   "source": [
    "### Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "555957bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table:\n",
      "   SVM Predictions  DT Predictions  NN Predictions  Voting Predictions  \\\n",
      "0                1               1               1                   1   \n",
      "1                0               0               0                   0   \n",
      "2                0               0               0                   0   \n",
      "3                0               1               1                   1   \n",
      "4                0               0               0                   0   \n",
      "5                1               0               1                   1   \n",
      "6                0               0               0                   0   \n",
      "7                1               1               1                   1   \n",
      "8                1               1               0                   1   \n",
      "9                1               1               1                   1   \n",
      "\n",
      "   Bagging Predictions  Stacking Predictions  Actual  SVM Correct  DT Correct  \\\n",
      "0                    1                     1       1         True        True   \n",
      "1                    0                     0       0         True        True   \n",
      "2                    0                     1       0         True        True   \n",
      "3                    1                     1       1        False        True   \n",
      "4                    0                     0       0         True        True   \n",
      "5                    1                     1       1         True       False   \n",
      "6                    0                     0       0         True        True   \n",
      "7                    1                     1       1         True        True   \n",
      "8                    1                     0       0        False       False   \n",
      "9                    1                     1       1         True        True   \n",
      "\n",
      "   NN Correct  Voting Correct  Bagging Correct  Stacking Correct  \n",
      "0        True            True             True              True  \n",
      "1        True            True             True              True  \n",
      "2        True            True             True             False  \n",
      "3        True            True             True              True  \n",
      "4        True            True             True              True  \n",
      "5        True            True             True              True  \n",
      "6        True            True             True              True  \n",
      "7        True            True             True              True  \n",
      "8        True           False            False              True  \n",
      "9        True            True             True              True  \n",
      "\n",
      "Accuracy:\n",
      "SVM Accuracy: 0.8\n",
      "DT Accuracy: 0.8\n",
      "NN Accuracy: 1.0\n",
      "Voting Accuracy: 0.9\n",
      "Bagging Accuracy: 0.9\n",
      "Stacking Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "new_data = pd.read_csv('./data/testing.csv')\n",
    "\n",
    "# Separate the features\n",
    "X_new = new_data.drop('success', axis=1)\n",
    "y_true = new_data['success']\n",
    "\n",
    "# Predict using the SVM model\n",
    "svm_predictions = svm_model.predict(X_new)\n",
    "\n",
    "# Predict using the Decision Tree model\n",
    "dt_predictions = dt_model.predict(X_new)\n",
    "\n",
    "# Predict using the Neural Network model\n",
    "nn_predictions = nn_model.predict(X_new)\n",
    "\n",
    "# Predict using the Ensemble(Voting)\n",
    "ensemble_predictions = ensemble_model.predict(X_new)\n",
    "\n",
    "# Predict using the Ensemble(Bagging)\n",
    "bagging_predictions = bagging_model.predict(X_new)\n",
    "\n",
    "# Predict using the Ensemble(Stacking)\n",
    "stacking_predictions = stacking_model.predict(X_new)\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame({'SVM Predictions': svm_predictions,\n",
    "                               'DT Predictions': dt_predictions,\n",
    "                               'NN Predictions': nn_predictions,\n",
    "                               'Voting Predictions': ensemble_predictions,\n",
    "                               'Bagging Predictions': bagging_predictions,\n",
    "                               'Stacking Predictions': stacking_predictions,\n",
    "                               'Actual': y_true})\n",
    "\n",
    "# Add a column to indicate incorrect predictions\n",
    "predictions_df['SVM Correct'] = predictions_df['SVM Predictions'] == predictions_df['Actual']\n",
    "predictions_df['DT Correct'] = predictions_df['DT Predictions'] == predictions_df['Actual']\n",
    "predictions_df['NN Correct'] = predictions_df['NN Predictions'] == predictions_df['Actual']\n",
    "predictions_df['Voting Correct'] = predictions_df['Voting Predictions'] == predictions_df['Actual']\n",
    "predictions_df['Bagging Correct'] = predictions_df['Bagging Predictions'] == predictions_df['Actual']\n",
    "predictions_df['Stacking Correct'] = predictions_df['Stacking Predictions'] == predictions_df['Actual']\n",
    "\n",
    "# Calculate accuracy for each model\n",
    "svm_accuracy = predictions_df['SVM Correct'].mean()\n",
    "dt_accuracy = predictions_df['DT Correct'].mean()\n",
    "nn_accuracy = predictions_df['NN Correct'].mean()\n",
    "ensemble_accuracy = predictions_df['Voting Correct'].mean()\n",
    "bagging_accuracy = predictions_df['Bagging Correct'].mean()\n",
    "stacking_accuracy = predictions_df['Stacking Correct'].mean()\n",
    "\n",
    "# Print the comparison table and accuracy\n",
    "print(\"Comparison Table:\")\n",
    "print(predictions_df)\n",
    "print(\"\\nAccuracy:\")\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"DT Accuracy:\", dt_accuracy)\n",
    "print(\"NN Accuracy:\", nn_accuracy)\n",
    "print(\"Voting Accuracy:\", ensemble_accuracy)\n",
    "print(\"Bagging Accuracy:\", bagging_accuracy)\n",
    "print(\"Stacking Accuracy:\", stacking_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bd798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
