{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ced3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./data/augmented_data.csv')\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = data.drop('success', axis=1)\n",
    "y = data['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc0cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Create a k-fold cross-validation object\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a4211ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.83       104\n",
      "           1       0.85      0.72      0.78        96\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.80      0.80       200\n",
      "weighted avg       0.81      0.81      0.80       200\n",
      "\n",
      "AUC-ROC Score: 0.8016826923076923\n"
     ]
    }
   ],
   "source": [
    "# Create the XGBoost model\n",
    "xgb_model = XGBClassifier(\n",
    "                     learning_rate =0.01,\n",
    "                     n_estimators=400,\n",
    "                     max_depth=4,\n",
    "                     min_child_weight=6,\n",
    "                     gamma=0)\n",
    "\n",
    "# Train the best model on the full training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "best_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the best model\n",
    "best_report = classification_report(y_test, best_predictions, output_dict=True)\n",
    "best_auc = roc_auc_score(y_test, best_predictions)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, best_predictions))\n",
    "print(\"AUC-ROC Score:\", best_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01951481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table:\n",
      "     XGB Predictions  Actual  XGB Correct\n",
      "0                  1       0        False\n",
      "1                  0       0         True\n",
      "2                  1       0        False\n",
      "3                  1       1         True\n",
      "4                  0       0         True\n",
      "..               ...     ...          ...\n",
      "121                1       0        False\n",
      "122                1       0        False\n",
      "123                0       0         True\n",
      "124                0       0         True\n",
      "125                1       0        False\n",
      "\n",
      "[126 rows x 3 columns]\n",
      "\n",
      "Accuracy:\n",
      "XGB Accuracy: 0.5634920634920635\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "new_data = pd.read_csv('./data/testing_encoded_data.csv')\n",
    "\n",
    "# Separate the features\n",
    "X_new = new_data.drop('success', axis=1)\n",
    "y_true = new_data['success']\n",
    "\n",
    "# Predict using the best XGBoost model\n",
    "xgb_predictions = xgb_model.predict(X_new)\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame({'XGB Predictions': xgb_predictions,\n",
    "                               'Actual': y_true})\n",
    "\n",
    "# Add a column to indicate incorrect predictions\n",
    "predictions_df['XGB Correct'] = predictions_df['XGB Predictions'] == predictions_df['Actual']\n",
    "\n",
    "# Calculate accuracy for XGB model\n",
    "xgb_accuracy = predictions_df['XGB Correct'].mean()\n",
    "\n",
    "# Print the comparison table and accuracy\n",
    "print(\"Comparison Table:\")\n",
    "print(predictions_df)\n",
    "print(\"\\nAccuracy:\")\n",
    "print(\"XGB Accuracy:\", xgb_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
