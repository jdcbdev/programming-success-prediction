{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15eac188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./data/augmented_data.csv')\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = data.drop('success', axis=1)\n",
    "y = data['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc2fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0baf1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Features:\n",
      "abstract                  0.100910\n",
      "shs_gpa                   0.183404\n",
      "p2                        0.171578\n",
      "p21                       0.109439\n",
      "p25                       0.111669\n",
      "p30                       0.129419\n",
      "p33                       0.120059\n",
      "s9                        0.114212\n",
      "s19                       0.119713\n",
      "s20                      -0.124845\n",
      "bscs                      0.130715\n",
      "bsit                     -0.121787\n",
      "class_rank_5              0.110160\n",
      "class_rank_none          -0.122872\n",
      "high_honor                0.109804\n",
      "awards_none              -0.112335\n",
      "class_president           0.116537\n",
      "class_none               -0.133929\n",
      "school_auditor            0.113201\n",
      "school_grade_level_rep    0.115394\n",
      "school_none              -0.105792\n",
      "income_10k                0.139563\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between features and the target variable\n",
    "correlations = X_train.corrwith(y_train)\n",
    "\n",
    "# Set a threshold for considering high correlation\n",
    "threshold = 0.1\n",
    "\n",
    "# Find the highly correlated features\n",
    "highly_correlated_features = correlations[correlations.abs() >= threshold]\n",
    "\n",
    "# Print the highly correlated features\n",
    "print(\"Highly Correlated Features:\")\n",
    "print(highly_correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad03726",
   "metadata": {},
   "source": [
    "### Classical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d2327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a k-fold cross-validation object\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_cv_scores = cross_val_score(svm_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "svm_accuracy = svm_cv_scores.mean()\n",
    "\n",
    "# Decision Tree (DT) model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_cv_scores = cross_val_score(dt_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "dt_accuracy = dt_cv_scores.mean()\n",
    "\n",
    "# Neural Network (NN) model\n",
    "nn_model = MLPClassifier()\n",
    "nn_cv_scores = cross_val_score(nn_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "nn_accuracy = nn_cv_scores.mean()\n",
    "\n",
    "# Train the models on the full training set\n",
    "svm_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "nn_predictions = nn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92cf74c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "            Model  CV Accuracy  Accuracy  F1-Score  Precision    Recall  \\\n",
      "0             SVM      0.73625     0.780  0.779205   0.780193  0.778846   \n",
      "1   Decision Tree      0.74250     0.825  0.824785   0.824692  0.824920   \n",
      "2  Neural Network      0.86625     0.930  0.929825   0.930349  0.929487   \n",
      "\n",
      "        AUC      Confusion Matrix  \n",
      "0  0.778846  [[84, 20], [24, 72]]  \n",
      "1  0.824920  [[86, 18], [17, 79]]  \n",
      "2  0.929487    [[98, 6], [8, 88]]  \n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "svm_report = classification_report(y_test, svm_predictions, output_dict=True)\n",
    "svm_auc = roc_auc_score(y_test, svm_predictions)\n",
    "\n",
    "dt_report = classification_report(y_test, dt_predictions, output_dict=True)\n",
    "dt_auc = roc_auc_score(y_test, dt_predictions)\n",
    "\n",
    "nn_report = classification_report(y_test, nn_predictions, output_dict=True)\n",
    "nn_auc = roc_auc_score(y_test, nn_predictions)\n",
    "\n",
    "# Calculate confusion matrix for each model\n",
    "svm_confusion = confusion_matrix(y_test, svm_predictions)\n",
    "dt_confusion = confusion_matrix(y_test, dt_predictions)\n",
    "nn_confusion = confusion_matrix(y_test, nn_predictions)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['SVM', 'Decision Tree', 'Neural Network'],\n",
    "    'CV Accuracy': [svm_accuracy, dt_accuracy, nn_accuracy],\n",
    "    'Accuracy': [svm_model.score(X_test, y_test), dt_model.score(X_test, y_test), nn_model.score(X_test, y_test)],\n",
    "    'F1-Score': [svm_report['macro avg']['f1-score'], dt_report['macro avg']['f1-score'], nn_report['macro avg']['f1-score']],\n",
    "    'Precision': [svm_report['macro avg']['precision'], dt_report['macro avg']['precision'], nn_report['macro avg']['precision']],\n",
    "    'Recall': [svm_report['macro avg']['recall'], dt_report['macro avg']['recall'], nn_report['macro avg']['recall']],\n",
    "    'AUC': [svm_auc, dt_auc, nn_auc],\n",
    "    'Confusion Matrix': [svm_confusion, dt_confusion, nn_confusion]\n",
    "})\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3e0ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Feature Importances (SVM Linear):\n",
      "                   Feature  SVM Importance\n",
      "89           highest_honor        1.821289\n",
      "98   class_project_manager        1.212668\n",
      "108         school_auditor        1.130361\n",
      "92             awards_none        1.114917\n",
      "73                    bscs        1.062360\n",
      "101             class_none        1.029394\n",
      "127              mother_na        0.978955\n",
      "81                      he        0.853504\n",
      "65                     s18        0.839842\n",
      "103  school_vice_president        0.811215\n"
     ]
    }
   ],
   "source": [
    "# Obtain feature importances for linear SVM model\n",
    "svm_feature_importances = abs(svm_model.coef_[0])\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'SVM Importance': svm_feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by SVM Importance values in descending order\n",
    "importances_df = importances_df.sort_values(by='SVM Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 feature importances\n",
    "top_10_importances = importances_df.head(10)\n",
    "print(\"Top 10 Feature Importances (SVM Linear):\")\n",
    "print(top_10_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7043303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Top 10 Feature Importances:\n",
      "          Feature  Importance\n",
      "6         shs_gpa    0.074407\n",
      "4    quantitative    0.070912\n",
      "18            p12    0.058292\n",
      "66            s19    0.054742\n",
      "21            p15    0.049071\n",
      "3         science    0.036465\n",
      "72         stotal    0.031699\n",
      "136    income_10k    0.031658\n",
      "67            s20    0.031607\n",
      "40            p34    0.028183\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for feature importances\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': dt_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance values in descending order\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 feature importances\n",
    "top_10_importances = importances_df.head(10)\n",
    "print(\"DT Top 10 Feature Importances:\")\n",
    "print(top_10_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cb4a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Feature Importances (Neural Network):\n",
      "          Feature  NN Importance\n",
      "79          humss       0.025269\n",
      "61            s14       0.021012\n",
      "29            p23       0.020336\n",
      "89  highest_honor       0.019815\n",
      "39            p33       0.018705\n",
      "5        abstract       0.016697\n",
      "68            s21       0.016521\n",
      "84         sports       0.015562\n",
      "11             p5       0.015525\n",
      "42            p36       0.014538\n"
     ]
    }
   ],
   "source": [
    "# Obtain feature importances for Neural Network model\n",
    "nn_feature_importances = abs(nn_model.coefs_[0].mean(axis=0))\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns[:len(nn_feature_importances)],\n",
    "    'NN Importance': nn_feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by NN Importance values in descending order\n",
    "importances_df = importances_df.sort_values(by='NN Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 feature importances\n",
    "top_10_importances = importances_df.head(10)\n",
    "print(\"Top 10 Feature Importances (Neural Network):\")\n",
    "print(top_10_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a2b9b",
   "metadata": {},
   "source": [
    "### Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b86e0765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the ensemble model using Voting Classifier\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('svm', svm_model), ('dt', dt_model), ('nn', nn_model)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Perform k-fold cross-validation on the ensemble model\n",
    "ensemble_cv_scores = cross_val_score(ensemble_model, X_train, y_train, cv=kf)\n",
    "ensemble_accuracy = ensemble_cv_scores.mean()\n",
    "\n",
    "# Train the ensemble model on the full training set\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "ensemble_predictions = ensemble_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the ensemble model\n",
    "ensemble_report = classification_report(y_test, ensemble_predictions, output_dict=True)\n",
    "ensemble_auc = roc_auc_score(y_test, ensemble_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2079fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the ensemble model using Bagging Classifier\n",
    "bagging_model = BaggingClassifier(base_estimator=SVC(kernel='linear'), n_estimators=10)\n",
    "bagging_cv_scores = cross_val_score(bagging_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "bagging_accuracy = bagging_cv_scores.mean()\n",
    "\n",
    "# Train the model on the full training set\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "bagging_predictions = bagging_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "bagging_report = classification_report(y_test, bagging_predictions, output_dict=True)\n",
    "bagging_auc = roc_auc_score(y_test, bagging_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a5deabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the ensemble model using Stacking Classifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('SVM', svm_model), ('Decision Tree', dt_model), ('Neural Network', nn_model)],\n",
    "    final_estimator=SVC(kernel='linear')\n",
    ")\n",
    "\n",
    "stacking_cv_scores = cross_val_score(stacking_model, X_train, y_train, cv=kf)  # Perform k-fold cross-validation\n",
    "stacking_accuracy = stacking_cv_scores.mean()\n",
    "\n",
    "# Train the model on the full training set\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "stacking_predictions = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "stacking_report = classification_report(y_test, stacking_predictions, output_dict=True)\n",
    "stacking_auc = roc_auc_score(y_test, stacking_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d186b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Results:\n",
      "      Model  CV Accuracy  Accuracy  F1-Score  Precision    Recall       AUC  \\\n",
      "0  Ensemble       0.8425     0.875  0.874293   0.877366  0.873397  0.873397   \n",
      "1   Bagging       0.7525     0.790  0.789474   0.789843  0.789263  0.789263   \n",
      "2  Stacking       0.8575     0.905  0.904807   0.905013  0.904647  0.904647   \n",
      "\n",
      "       Confusion Matrix  \n",
      "0   [[95, 9], [16, 80]]  \n",
      "1  [[84, 20], [22, 74]]  \n",
      "2   [[95, 9], [10, 86]]  \n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix for each model\n",
    "ensemble_confusion = confusion_matrix(y_test, ensemble_predictions)\n",
    "bagging_confusion = confusion_matrix(y_test, bagging_predictions)\n",
    "stacking_confusion = confusion_matrix(y_test, stacking_predictions)\n",
    "\n",
    "# Create a DataFrame for the ensemble models\n",
    "ensemble_results = pd.DataFrame({\n",
    "    'Model': ['Ensemble', 'Bagging', 'Stacking'],\n",
    "    'CV Accuracy': [ensemble_accuracy, bagging_accuracy, stacking_accuracy],\n",
    "    'Accuracy': [ensemble_model.score(X_test, y_test), bagging_model.score(X_test, y_test), stacking_model.score(X_test, y_test)],\n",
    "    'F1-Score': [ensemble_report['macro avg']['f1-score'], bagging_report['macro avg']['f1-score'], stacking_report['macro avg']['f1-score']],\n",
    "    'Precision': [ensemble_report['macro avg']['precision'], bagging_report['macro avg']['precision'], stacking_report['macro avg']['precision']],\n",
    "    'Recall': [ensemble_report['macro avg']['recall'], bagging_report['macro avg']['recall'], stacking_report['macro avg']['recall']],\n",
    "    'AUC': [ensemble_auc, bagging_auc, stacking_auc],\n",
    "    'Confusion Matrix': [ensemble_confusion, bagging_confusion, stacking_confusion]\n",
    "})\n",
    "\n",
    "# Print the results of the ensemble models\n",
    "print(\"Ensemble Model Results:\")\n",
    "print(ensemble_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb233f0",
   "metadata": {},
   "source": [
    "### Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "555957bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table:\n",
      "     SVM Predictions  DT Predictions  NN Predictions  Voting Predictions  \\\n",
      "0                  1               1               0                   1   \n",
      "1                  1               0               0                   0   \n",
      "2                  0               1               0                   0   \n",
      "3                  0               0               1                   0   \n",
      "4                  0               1               1                   0   \n",
      "..               ...             ...             ...                 ...   \n",
      "121                0               1               1                   0   \n",
      "122                1               1               1                   1   \n",
      "123                0               1               0                   0   \n",
      "124                1               0               1                   1   \n",
      "125                0               0               1                   0   \n",
      "\n",
      "     Bagging Predictions  Stacking Predictions  Actual  SVM Correct  \\\n",
      "0                      1                     1       0        False   \n",
      "1                      0                     0       0        False   \n",
      "2                      0                     0       0         True   \n",
      "3                      0                     1       1        False   \n",
      "4                      0                     0       0         True   \n",
      "..                   ...                   ...     ...          ...   \n",
      "121                    0                     0       0         True   \n",
      "122                    1                     1       0        False   \n",
      "123                    0                     0       0         True   \n",
      "124                    1                     1       0        False   \n",
      "125                    0                     1       0         True   \n",
      "\n",
      "     DT Correct  NN Correct  Voting Correct  Bagging Correct  Stacking Correct  \n",
      "0         False        True           False            False             False  \n",
      "1          True        True            True             True              True  \n",
      "2         False        True            True             True              True  \n",
      "3         False        True           False            False              True  \n",
      "4         False       False            True             True              True  \n",
      "..          ...         ...             ...              ...               ...  \n",
      "121       False       False            True             True              True  \n",
      "122       False       False           False            False             False  \n",
      "123       False        True            True             True              True  \n",
      "124        True       False           False            False             False  \n",
      "125        True       False            True             True             False  \n",
      "\n",
      "[126 rows x 13 columns]\n",
      "\n",
      "Accuracy:\n",
      "SVM Accuracy: 0.5952380952380952\n",
      "DT Accuracy: 0.5079365079365079\n",
      "NN Accuracy: 0.5396825396825397\n",
      "Voting Accuracy: 0.5793650793650794\n",
      "Bagging Accuracy: 0.6031746031746031\n",
      "Stacking Accuracy: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "new_data = pd.read_csv('./data/testing_encoded_data.csv')\n",
    "\n",
    "# Separate the features\n",
    "X_new = new_data.drop('success', axis=1)\n",
    "y_true = new_data['success']\n",
    "\n",
    "# Predict using the SVM model\n",
    "svm_predictions = svm_model.predict(X_new)\n",
    "\n",
    "# Predict using the Decision Tree model\n",
    "dt_predictions = dt_model.predict(X_new)\n",
    "\n",
    "# Predict using the Neural Network model\n",
    "nn_predictions = nn_model.predict(X_new)\n",
    "\n",
    "# Predict using the Ensemble(Voting)\n",
    "ensemble_predictions = ensemble_model.predict(X_new)\n",
    "\n",
    "# Predict using the Ensemble(Bagging)\n",
    "bagging_predictions = bagging_model.predict(X_new)\n",
    "\n",
    "# Predict using the Ensemble(Stacking)\n",
    "stacking_predictions = stacking_model.predict(X_new)\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame({'SVM Predictions': svm_predictions,\n",
    "                               'DT Predictions': dt_predictions,\n",
    "                               'NN Predictions': nn_predictions,\n",
    "                               'Voting Predictions': ensemble_predictions,\n",
    "                               'Bagging Predictions': bagging_predictions,\n",
    "                               'Stacking Predictions': stacking_predictions,\n",
    "                               'Actual': y_true})\n",
    "\n",
    "# Add a column to indicate incorrect predictions\n",
    "predictions_df['SVM Correct'] = predictions_df['SVM Predictions'] == predictions_df['Actual']\n",
    "predictions_df['DT Correct'] = predictions_df['DT Predictions'] == predictions_df['Actual']\n",
    "predictions_df['NN Correct'] = predictions_df['NN Predictions'] == predictions_df['Actual']\n",
    "predictions_df['Voting Correct'] = predictions_df['Voting Predictions'] == predictions_df['Actual']\n",
    "predictions_df['Bagging Correct'] = predictions_df['Bagging Predictions'] == predictions_df['Actual']\n",
    "predictions_df['Stacking Correct'] = predictions_df['Stacking Predictions'] == predictions_df['Actual']\n",
    "\n",
    "# Calculate accuracy for each model\n",
    "svm_accuracy = predictions_df['SVM Correct'].mean()\n",
    "dt_accuracy = predictions_df['DT Correct'].mean()\n",
    "nn_accuracy = predictions_df['NN Correct'].mean()\n",
    "ensemble_accuracy = predictions_df['Voting Correct'].mean()\n",
    "bagging_accuracy = predictions_df['Bagging Correct'].mean()\n",
    "stacking_accuracy = predictions_df['Stacking Correct'].mean()\n",
    "\n",
    "# Print the comparison table and accuracy\n",
    "print(\"Comparison Table:\")\n",
    "print(predictions_df)\n",
    "print(\"\\nAccuracy:\")\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"DT Accuracy:\", dt_accuracy)\n",
    "print(\"NN Accuracy:\", nn_accuracy)\n",
    "print(\"Voting Accuracy:\", ensemble_accuracy)\n",
    "print(\"Bagging Accuracy:\", bagging_accuracy)\n",
    "print(\"Stacking Accuracy:\", stacking_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bd798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
